global:
  domain: crucible
  namespace: default
  version: "0.0.0"
  security:
    allowInsecureImages: true

# Provision an NFS Server for apps to use for PVCs
# https://artifacthub.io/packages/helm/kvaps/nfs-server-provisioner
nfs-server-provisioner:
  persistence:
    enabled: true

# Deploy an ingress-nginx ingress controller
# https://kubernetes.github.io/ingress-nginx/
#
ingress-nginx:
  controller:
    config:
      hsts: "false"
      annotations-risk-level: critical
    allowSnippetAnnotations: true
    updateStrategy:
      type: RollingUpdate
  tcp:
    2049: "{{ .Release.Namespace }}/{{ .Release.Name }}-nfs-server-provisioner:2049"

# Deploy a postgres database
# https://github.com/self-hosters-by-night/helm-charts/tree/main/charts/postgres
postgresql:
  enabled: true
  image:
    registry: docker.io
    repository: postgres
    tag: "16"
  env:
    vars:
      # default postgres username and database
      POSTGRES_USER: "postgres"
      POSTGRES_DB: "postgres"
    fromSecret:
      # Postgres passsword comes from a secret
      # The postgres sub-chart does not support templating here
      POSTGRES_PASSWORD:
        from: crucible-postgresql
        key: postgres-password
  persistence:
    enabled: true
    annotations: {}
    storageClass: null
    accessModes:
      - ReadWriteOnce
    size: "1Gi"
    selector: null

# Deploy pgadmin4 for managing the database
# https://artifacthub.io/packages/helm/runix/pgadmin4
pgadmin4:
  enabled: true
  fullnameOverride: crucible-pgadmin
  existingSecret: crucible-pgadmin
  env:
    # email address for the default user
    email: pgadmin@crucible.dev
    contextPath: /pgadmin
    variables:
      - name: PGADMIN_CONFIG_UPGRADE_CHECK_ENABLED
        value: "False"
      # ignore ssl errors caused by self-signed cert
      - name: PGADMIN_CONFIG_SSL_VERIFY
        value: "False"
  serverDefinitions:
    enabled: true
    resourceType: Secret
    servers:
      # configure the postgres database to connect on deploy
      crucible-postgres:
        Name: "Crucible Postgres"
        Group: "Servers"
        Host: "{{ .Release.Name }}-postgresql"
        Port: "5432"
        Username: "postgres"
        SSLMode: "prefer"
        MaintenanceDB: "postgres"
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - host: "{{ .Values.global.domain }}"
        paths:
          - path: /pgadmin
            pathType: Prefix
    tls:
      - hosts:
          - "{{ .Values.global.domain }}"
        secretName: crucible-cert

# Deploy Keycloak IdP
# https://artifacthub.io/packages/helm/bitnami/keycloak
keycloak:
  enabled: true
  image:
    # This bitnamilegacy image requires allowing insecure images
    repository: bitnamilegacy/keycloak
  auth:
    # default admin creds come from an existing secret
    adminUser: "keycloak-admin"
    existingSecret: '{{ include "crucible.fullname" . }}-auth'
  proxyHeaders: xforwarded
  httpRelativePath: /keycloak/
  ingress:
    enabled: true
    ingressClassName: nginx
    hostname: "{{ .Values.global.domain }}"
    annotations:
      nginx.ingress.kubernetes.io/server-snippet: |
        location ~ ^/keycloak/?$ {
          return 302 $scheme://$host/keycloak/admin/crucible/console/;
        }
    tls: true
    extraTls:
      - hosts:
          - "{{ .Values.global.domain }}"
        secretName: crucible-cert
  # import realm on startup
  # If the realm already exists, keycloak will not overwrite it
  #    (even if the realm.json is different than keycloak's config)
  extraEnvVars:
    - name: KEYCLOAK_EXTRA_ARGS
      value: "--import-realm"
  extraVolumes:
    - name: realm-import
      configMap:
        name: '{{ include "crucible.fullname" . }}-config-cli'
  extraVolumeMounts:
    - name: realm-import
      mountPath: /opt/bitnami/keycloak/data/import
      readOnly: true
  # Use the external postgres instead of the one provided by the bitnami chart
  postgresql:
    enabled: false
  externalDatabase:
    host: "{{ .Release.Name }}-postgresql"
    user: postgres
    database: keycloak
    existingSecret: "{{ .Release.Name }}-postgresql"
    existingSecretPasswordKey: postgres-password

# Deploy TopoMojo
# https://github.com/cmu-sei/helm-charts/tree/main/charts/topomojo
topomojo:
  enabled: true
  topomojo-api:
    ingress:
      enabled: true
      className: nginx
      annotations:
        nginx.ingress.kubernetes.io/proxy-body-size: 6g
      hosts:
        - host: "{{ .Values.global.domain }}"
          paths:
            - path: /topomojo/api
              pathType: ImplementationSpecific
            - path: /topomojo/hub
              pathType: ImplementationSpecific
            - path: /topomojo/docs
              pathType: ImplementationSpecific
      tls:
        - hosts:
            - "{{ .Values.global.domain }}"
          secretName: crucible-cert
    storage:
      existing: '{{ include "crucible.fullname" . }}-nfs'
    # This secret includes a database connection string and a custom CA cert
    existingSecret: '{{ include "crucible.fullname" . }}-custom'
    # The custom start command allows TopoMojo to trust a custom CA cert (self-signed)
    customStart:
      command: ["/bin/sh"]
      args: ["/home/app/start/start.sh"]
      binaryFiles: {}
      files:
        start.sh: |
          cd /home/app && SSL_CERT_FILE=/home/app/conf/cacert.crt dotnet TopoMojo.Api.dll
    env:
      PathBase: /topomojo
      # postgres database connection string provided by secret
      Database__Provider: PostgreSQL
      FileUpload__IsoRoot: /mnt/tm
      FileUpload__TopoRoot: /mnt/tm
      FileUpload__DocRoot: /mnt/tm/_docs
      # Configure OIDC to use Keycloak
      Oidc__Authority: https://{{ .Values.global.domain }}/keycloak/realms/crucible
      Oidc__Audience: topomojo
      Oidc__MetadataAddress: https://{{ .Values.global.domain }}/keycloak/realms/crucible/.well-known/openid-configuration
      Oidc__RequireHttpsMetadata: false
      OpenApi__Client__AuthorizationUrl: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/auth
      OpenApi__Client__TokenUrl: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/token
      OpenApi__Client__ClientId: topomojo.api
      Headers__Cors__Origins__0: https://{{ .Values.global.domain }}
      Headers__Forwarding__TargetHeaders: All
      # Core__ConsoleHost: "{{ .Values.global.domain }}/console"
      # Pod__ConsoleUrl: "{{ .Values.global.domain }}/console"
  topomojo-ui:
    ingress:
      enabled: true
      className: nginx
      annotations:
        nginx.ingress.kubernetes.io/proxy-body-size: 6g
      hosts:
        - host: "{{ .Values.global.domain }}"
          paths:
            - path: /topomojo
              pathType: ImplementationSpecific
      tls:
        - hosts:
            - "{{ .Values.global.domain }}"
          secretName: crucible-cert
    basehref: /topomojo
    settingsYaml:
      appname: TopoMojo
      oidc:
        # Use Keycloak client configurations
        authority: https://{{ .Values.global.domain }}/keycloak/realms/crucible
        client_id: topomojo.ui
        redirect_uri: https://{{ .Values.global.domain }}/topomojo/oidc
        silent_redirect_uri: https://{{ .Values.global.domain }}/topomojo/oidc-silent.html
        post_logout_redirect_uri: https://{{ .Values.global.domain }}/topomojo
        response_type: code
        scope: openid profile topomojo
        automaticSilentRenew: true
        includeIdTokenInSilentRenew: false
        filterProtocolClaims: true
        loadUserInfo: true
        accessTokenExpiringNotificationTime: 120
        monitorSession: false
        useLocalStorage: true

# Deploy Player
# https://github.com/cmu-sei/helm-charts/tree/main/charts/player
player:
  enabled: true
  player-api:
    # use a configmap to define the custom ca cert
    certificateMap: "crucible-ca-cert"
    ingress:
      enabled: true
      className: nginx
      annotations:
        nginx.ingress.kubernetes.io/proxy-read-timeout: "86400"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "86400"
        nginx.ingress.kubernetes.io/use-regex: "true"
      hosts:
        - host: "{{ .Values.global.domain }}"
          paths:
            - path: /player/(hubs|swagger|api)
              pathType: ImplementationSpecific
      tls:
        - hosts:
            - "{{ .Values.global.domain }}"
          secretName: crucible-cert
    # This secret contains the postgres connection string
    existingSecret: "{{ .Release.Name }}-player-api-custom"
    env:
      PathBase: /player
      # Use Keycloak client configurations
      Authorization__Authority: https://{{ .Values.global.domain }}/keycloak/realms/crucible
      Authorization__AuthorizationUrl: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/auth
      Authorization__TokenUrl: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/token
      Authorization__MetadataAddress: https://{{ .Values.global.domain }}/keycloak/realms/crucible/.well-known/openid-configuration
      Authorization__AuthorizationScope: "player"
      Authorization__ClientId: player.api
      Authorization__RequireHttpsMetadata: "false"
      CorsPolicy__Origins__0: https://{{ .Values.global.domain }}
      # Trust the custom ca-cert
      SSL_CERT_FILE: /usr/local/share/ca-certificates/crucible-dev.crt
      SSL_CERT_DIR: /usr/local/share/ca-certificates
      # Configure an OTLP collector for sending opentelemetry
      # Use the kubernetes cluster address for the collector
      OTEL_EXPORTER_OTLP_ENDPOINT: crucible-grafana-alloy:4317
  player-ui:
    ingress:
      enabled: true
      className: nginx
      hosts:
        - host: "{{ .Values.global.domain }}"
          paths:
            - path: /player
              pathType: ImplementationSpecific
      tls:
        - hosts:
            - "{{ .Values.global.domain }}"
          secretName: crucible-cert
    env:
      APP_BASEHREF: /player
    settingsYaml:
      ApiUrl: https://{{ .Values.global.domain }}/player
      OIDCSettings:
        authority: https://{{ .Values.global.domain }}/keycloak/realms/crucible
        client_id: player.ui
        redirect_uri: https://{{ .Values.global.domain }}/player/auth-callback
        post_logout_redirect_uri: https://{{ .Values.global.domain }}/player
        response_type: code
        scope: openid profile player
        automaticSilentRenew: true
        silent_redirect_uri: https://{{ .Values.global.domain }}/player/auth-callback-silent.html
      NotificationsSettings:
        url: https://{{ .Values.global.domain }}/player/hubs
  vm-api:
    # use a configmap to define the custom ca cert
    certificateMap: "crucible-ca-cert"
    ingress:
      enabled: true
      className: nginx
      hosts:
        - host: "{{ .Values.global.domain }}"
          paths:
            - path: /vm/(notifications|hubs|api|swagger)
              pathType: ImplementationSpecific
      tls:
        - hosts:
            - "{{ .Values.global.domain }}"
          secretName: crucible-cert
    # This secret contains 2 different postgres connection strings that are required for this application
    existingSecret: "{{ .Release.Name }}-vm-api-custom"
    env:
      PathBase: /vm
      VmUsageLogging__Enabled: "true"
      Authorization__Authority: https://{{ .Values.global.domain }}/keycloak/realms/crucible
      Authorization__AuthorizationUrl: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/auth
      Authorization__TokenUrl: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/token
      Authorization__RequireHttpsMetadata: "false"
      Authorization__ClientId: player.vm.api
      ClientSettings__urls__playerApi: https://{{ .Values.global.domain }}/player
      CorsPolicy__Origins__0: https://{{ .Values.global.domain }}
  vm-ui:
    ingress:
      enabled: true
      className: nginx
      hosts:
        - host: "{{ .Values.global.domain }}"
          paths:
            - path: /vm
              pathType: ImplementationSpecific
      tls:
        - hosts:
            - "{{ .Values.global.domain }}"
          secretName: crucible-cert
    env:
      APP_BASEHREF: /vm
    settingsYaml:
      ApiUrl: https://{{ .Values.global.domain }}/vm/api
      ApiPlayerUrl: https://{{ .Values.global.domain }}/player
      UserFollowUrl: https://{{ .Values.global.domain }}/console/user/{userId}/view/{viewId}/console
      OIDCSettings:
        authority: https://{{ .Values.global.domain }}/keycloak/realms/crucible
        client_id: player.vm.ui
        redirect_uri: https://{{ .Values.global.domain }}/vm/auth-callback
        post_logout_redirect_uri: https://{{ .Values.global.domain }}/vm
        response_type: code
        scope: openid profile player player-vm
        automaticSilentRenew: true
        silent_redirect_uri: https://{{ .Values.global.domain }}/vm/auth-callback-silent.html
  console-ui:
    ingress:
      enabled: true
      className: nginx
      hosts:
        - host: "{{ .Values.global.domain }}"
          paths:
            - path: /console
              pathType: ImplementationSpecific
      tls:
        - hosts:
            - "{{ .Values.global.domain }}"
          secretName: crucible-cert
    env:
      APP_BASEHREF: /console
    settingsYaml:
      ConsoleApiUrl: https://{{ .Values.global.domain }}/vm
      OIDCSettings:
        authority: https://{{ .Values.global.domain }}/keycloak/realms/crucible
        client_id: player.vm.console.ui
        redirect_uri: https://{{ .Values.global.domain }}/console/auth-callback
        post_logout_redirect_uri: https://{{ .Values.global.domain }}/console
        response_type: code
        scope: openid profile player player-vm
        automaticSilentRenew: true

# Deploy Prometheus for metrics collection
# https://artifacthub.io/packages/helm/prometheus-community/prometheus
prometheus:
  enabled: true
  server:
    prefixURL: ""
    baseURL: ""
    extraArgs:
      web.enable-remote-write-receiver: "" # enable the remote-write-receiver for Grafana-Alloy writing

# Deploy Grafana for dashboards/visualization
# https://artifacthub.io/packages/helm/grafana/grafana
grafana:
  enabled: true
  # ingress hosts grafana at https://<domain>/grafana
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      nginx.ingress.kubernetes.io/configuration-snippet: |
        rewrite ^(/grafana)$ $1/ break;
    hosts:
      - "{{ .Values.global.domain }}"
    path: /grafana
    pathType: Prefix
    tls:
      - secretName: crucible-cert
        hosts:
          - "{{ .Values.global.domain }}"
  grafana.ini:
    server:
      root_url: https://{{ .Values.global.domain }}/grafana/
      serve_from_sub_path: true
    auth:
      disable_login_form: true
      signout_redirect_url: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/logout?redirect_uri=https://{{ .Values.global.domain }}/grafana/
    auth.generic_oauth:
      enabled: true
      name: Keycloak
      allow_sign_up: true
      client_id: grafana
      client_secret: ${GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET}
      scopes: openid profile email
      auth_url: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/auth
      token_url: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/token
      api_url: https://{{ .Values.global.domain }}/keycloak/realms/crucible/protocol/openid-connect/userinfo
      email_attribute_path: email
      login_attribute_path: email
      name_attribute_path: preferred_username
      role_attribute_path: "contains(realm_access.roles[*], 'Administrator') && 'Admin' || 'Viewer'"

  # configure datasources from Prometheus (metrics), Loki (logs), Tempo (Otel traces)
  # data sources use cluster service addresses
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          uid: prometheus
          type: prometheus
          access: proxy
          url: http://{{ .Release.Name }}-prometheus-server
          isDefault: true
        - name: Loki
          uid: loki
          type: loki
          access: proxy
          url: http://{{ .Release.Name }}-loki:3100
          jsonData:
            maxLines: 1000
        - name: Tempo
          uid: tempo
          type: tempo
          access: proxy
          url: http://{{ .Release.Name }}-tempo:3100
          jsonData:
            httpMethod: GET
            tracesToMetrics:
              datasourceUid: prometheus
            serviceMap:
              datasourceUid: prometheus

  # Add custom cert as trusted via the configmap
  env:
    SSL_CERT_FILE: /etc/ssl/certs/combined-ca/ca-certificates.crt
    GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET: 516aea1d6915825e2dd757834a34386bd21c942c6c42e7cbc52ef2ba7cfb5518
  extraInitContainers:
    - name: grafana-ca-bundle
      image: alpine:3.19
      command:
        - /bin/sh
        - -c
        - |
          set -e
          cp /etc/ssl/certs/ca-certificates.crt /ca-bundle/ca-certificates.crt
          cat /crucible-ca/crucible-dev.crt >> /ca-bundle/ca-certificates.crt
          if [ -f /crucible-ca/zscaler-ca.crt ]; then cat /crucible-ca/zscaler-ca.crt >> /ca-bundle/ca-certificates.crt; fi
      volumeMounts:
        - name: ca-bundle
          mountPath: /ca-bundle
        - name: crucible-ca
          mountPath: /crucible-ca
  extraVolumes:
    - name: crucible-ca
      configMap:
        name: crucible-ca-cert
        items:
          - key: crucible-dev.crt
            path: crucible-dev.crt
          - key: zscaler-ca.crt
            path: zscaler-ca.crt
    - name: ca-bundle
      emptyDir: {}
  extraVolumeMounts:
    - name: crucible-ca
      mountPath: /crucible-ca/crucible-dev.crt
      subPath: crucible-dev.crt
      readOnly: true
    - name: ca-bundle
      mountPath: /etc/ssl/certs/combined-ca
      readOnly: true

# Deploy Grafana Loki for log collection
# https://artifacthub.io/packages/helm/grafana/loki
loki:
  enabled: true
  # SingleBinary mode is good for a small dev cluster and runs the loki server in one pod
  deploymentMode: SingleBinary
  gateway:
    enabled: false
  singleBinary:
    replicas: 1
    persistence:
      enabled: true
      size: 5Gi

    # Add custom cert as trusted via the configmap
    extraEnv:
      - name: SSL_CERT_FILE
        value: /usr/local/share/ca-certificates/crucible-dev.crt
    extraVolumes:
      - name: crucible-ca
        configMap:
          name: crucible-ca-cert
          items:
            - key: crucible-dev.crt
              path: crucible-dev.crt
    extraVolumeMounts:
      - name: crucible-ca
        mountPath: /usr/local/share/ca-certificates/crucible-dev.crt
        subPath: crucible-dev.crt
        readOnly: true
  read:
    replicas: 0
  write:
    replicas: 0
  backend:
    replicas: 0
  loki:
    # auth is disabled to simplify deployment
    # this service is kubernetes-internal
    auth_enabled: false
    storage:
      type: filesystem
      filesystem:
        chunks_directory: /var/loki/chunks
        rules_directory: /var/loki/rules
    commonConfig:
      replication_factor: 1
    useTestSchema: true

# Deploy Grafana Temp for OpenTelemetry Trace collection
# https://artifacthub.io/packages/helm/grafana/tempo
tempo:
  enabled: true
  replicas: 1
  tempo:
    # Use local storage for trace data
    storage:
      trace:
        backend: local
        local:
          path: /var/tempo/traces
        wal:
          path: /var/tempo/wal
    # The OTLP receiver listens for gRPC and HTTP
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"
          http:
            endpoint: "0.0.0.0:4318"
  persistence:
    enabled: true
    size: 5Gi
    storageClass: null
  service:
    type: ClusterIP
  tempoQuery:
    enabled: false

# Deploy Grafana Alloy as an OpenTelemetry Collector
# Apps will send OTLP data to Grafana Alloy, which when forwards the data to other services.
# metrics to Prometheus, logs to Loki, and traces to Tempo
# https://artifacthub.io/packages/helm/grafana/alloy
grafana-alloy:
  enabled: true
  fullnameOverride: "crucible-grafana-alloy"
  controller:
    type: daemonset
    volumes:
      # Alloy Controller to trust the custom cert
      extra:
        - name: crucible-ca
          configMap:
            name: crucible-ca-cert
            items:
              - key: crucible-dev.crt
                path: crucible-dev.crt
  alloy:
    stabilityLevel: experimental

    # Alloy app to trust the custom cert
    extraEnv:
      - name: SSL_CERT_FILE
        value: /usr/local/share/ca-certificates/crucible-dev.crt
    mounts:
      varlog: true
      dockercontainers: true
      extra:
        - name: crucible-ca
          mountPath: /usr/local/share/ca-certificates/crucible-dev.crt
          subPath: crucible-dev.crt
          readOnly: true

    # Extra ports to handle the otel grpc/http receivers
    extraPorts:
      - name: otlp-grpc
        port: 4317
        targetPort: 4317
        protocol: TCP
      - name: otlp-http
        port: 4318
        targetPort: 4318
        protocol: TCP
    configMap:
      # Grafana Alloy Configuration
      # Reference: https://grafana.com/docs/alloy/latest/reference/components/
      # Reference: https://grafana.com/docs/alloy/latest/collect/logs-in-kubernetes/
      # Reference: https://grafana.com/docs/alloy/latest/collect/opentelemetry-to-lgtm-stack/
      # Consider adding the following in the future:
      # 1. Kubernetes Cluster Events: https://grafana.com/docs/alloy/latest/collect/logs-in-kubernetes/#kubernetes-cluster-events
      # 2. Kuberenetes Node Logs: https://grafana.com/docs/alloy/latest/collect/logs-in-kubernetes/#system-logs
      # 3. Grafana Alloy Meta-Metrics (metrics about the metrics collector): https://grafana.com/docs/alloy/latest/collect/metamonitoring/
      content: |-
        logging {
          level = "info"
        }

        // Begin Kubernetes discovery configuration

        // discovery.kubernetes allows you to find scrape targets from Kubernetes resources.
        // this spec will automatically discover all kubernetes pods in the cluster
        discovery.kubernetes "pods" {
          role = "pod"
        }

        // discovery.relabel rewrites the label set of the input targets by applying one or more relabeling rules.
        // this simplifies the names of labels
        discovery.relabel "pod_logs" {
          targets = discovery.kubernetes.pods.targets

          // Label creation - "namespace" field from "__meta_kubernetes_namespace"
          rule {
            source_labels = ["__meta_kubernetes_namespace"]
            action        = "replace"
            target_label  = "namespace"
          }

          // Label creation - "pod" field from "__meta_kubernetes_pod_name"
          rule {
            source_labels = ["__meta_kubernetes_pod_name"]
            action        = "replace"
            target_label  = "pod"
          }

          // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
          rule {
            source_labels = ["__meta_kubernetes_pod_container_name"]
            action        = "replace"
            target_label  = "container"
          }

          // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
          rule {
            source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
            action        = "replace"
            target_label  = "app"
          }

          // Label creation -  "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
          // Concatenate values __meta_kubernetes_namespace/__meta_kubernetes_pod_container_name
          rule {
            source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
            action        = "replace"
            target_label  = "job"
            separator     = "/"
            replacement   = "$1"
          }
        }

        // End Kubernetes discovery configuration

        // Begin Loki configuration

        // loki.source.kubernetes tails logs from Kubernetes containers using the Kubernetes API.
        loki.source.kubernetes "pods" {
          targets    = discovery.relabel.pod_logs.output
          forward_to = [loki.process.pods.receiver]
        }

        // loki.process receives log entries from other Loki components, applies one or more processing stages,
        // and forwards the results to the list of receivers in the component's arguments.
        loki.process "pods" {
          stage.docker {}
          forward_to = [loki.write.default.receiver]
        }

        // loki.write sends logs to the Loki endpoint
        loki.write "default" {
          endpoint {
            url = "http://{{ .Release.Name }}-loki:3100/loki/api/v1/push"
          }
        }

        // End Loki configuration

        // Begin Prometheus configuration

        // deliver metrics to the prometheus endpoint
        prometheus.remote_write "default" {
          endpoint {
            url = "http://{{ .Release.Name }}-prometheus-server/api/v1/write"
          }
        }

        // scrape prometheus metrics from kubernetes pods
        prometheus.scrape "pods" {
          targets    = discovery.kubernetes.pods.targets
          forward_to = [prometheus.remote_write.default.receiver]
        }

        // End Prometheus configuration

        // Begin OpenTelemetry configuration

        // Export otel logs to Loki
        otelcol.exporter.loki "default" {
          forward_to = [loki.write.default.receiver]
        }

        // Export otel traces to Tempo via gRPC
        otelcol.exporter.otlp "default" {
          client {
            endpoint = "{{ .Release.Name }}-tempo:4317"
            // insecure is ok since this just stays in the cluster
            tls {
              insecure = true
            }
          }
        }

        // Export otel metrics to Prometheus
        otelcol.exporter.prometheus "default" {
          forward_to = [prometheus.remote_write.default.receiver]
        }

        // Batch otel exports to reduce network chatter
        otelcol.processor.batch "default" {
          output {
            metrics = [otelcol.exporter.prometheus.default.input]
            logs    = [otelcol.exporter.loki.default.input]
            traces  = [otelcol.exporter.otlp.default.input]
          }
        }

        // Configure an otel receiver for apps to send otel to
        // This is a compatible Otel Collector for http and grpc
        otelcol.receiver.otlp "default" {
          grpc {
            endpoint = "0.0.0.0:4317"
          }

          http {
            endpoint = "0.0.0.0:4318"
          }

          // Send output to the batch processor
          // Batch processor then forwards to the correct services
          output {
            metrics = [otelcol.processor.batch.default.input]
            logs    = [otelcol.processor.batch.default.input]
            traces  = [otelcol.processor.batch.default.input]
          }
        }

        // End OpenTelemetry configuration
